## 《统计学习方法》

下面是这本书的杂记，是重读此书零星的思考。  

### 监督学习和无监督学习

监督学习分为学习和预测两个过程，学习有两种方法，通过建立条件概率模型或者得到决策函数。  
对于概率模型，有一个前提假设： **训练数据和测试数据是依联合概率分布 $P(X,Y)$ 独立同分布产生的**；  
这里需要解释一下加粗句子的意思。

依联合概率独立同分布的意思：  
- (x,y)~p(x,y)：任意的(x,y)，包括训练集和测试集都服从该分布p(x,y);
- $p(x_m,y_m)$ 的概率不依赖于 $p(x_n,y_n)$ ，也就是当前出现的样本$(x_m,y_m)$，对后续产生的样本没有影响；
- 此处的独立不是常见的 `x,y` 的独立，若是，则 $p(x,y)=p(x)p(y)$，那么输入 `x` 和输出 `y` 没有关系了，因为独立，那么条件概率模型没法建立；
- 依联合概率独立同分布，是将模型简化，易于建立模型。

### MAP和贝叶斯估计
- 最大后验估计是贝叶斯学派的观点，~~也叫贝叶斯估计，这点理解有误~~(准确的理解，参见下面一节：`MAP、贝叶斯估计和朴素贝叶斯分析`），该估计将被预测模型(概率分布模型)的参数当做是随机变量，而最大似然估计只是将该参数当做是未知确定的量来处理；  
- `MAP` 把模型参数当做自变量，那么就要想办法获得该参数的概率分布，但训练集是依代表训练集的随机变量的概率模型中抽取出来的，虽然训练集中包含了模型参数的信息，但毕竟和参数所服从的概率分布不大；如果我们要依赖训练集学习参数的概率分布，那么就只能学习后验概率；假设随机变量是 $D$，随机变量$\theta$表示模型参数，根据贝叶斯定理：  
    $$
    P(\theta|D) = \frac{P(\theta)P(D|\theta)} {P(D)} \tag{1}
    $$
    其中$P(\theta)$是自己假设的关于$\theta$的先验概率，$P(\theta|D)$ 是训练数据修正后的关于 $\theta$ 的分布；

- $P(\theta|D)$ 叫后验概率，~~其分布的确定依靠后验概率最大，观察公式 $(1)$，分母$P(D)$，理解有误~~，(不是所谓的后验概率最大化，因为这里后验概率是一个关于$\theta$的分布，说分布的确定依赖后验概率最大化完全是概念的混乱，后验概率最大化是一个最值问题，反推的结果是$\theta$确定的值，这是MAP估计)  
- 那么给定新的输入，如何预测新的输出？
    $$
    P(x|D) = \int P(x|\theta, D)P(\theta|D)\,d\theta  \tag{2}
    $$
    公式$(2)$ 中x是要预测新的输出，对$\theta$进行全积分，结果得到给定新的输入和原先训练集$D$下的新的输出的全概率分布，新的输出一般取该全概率分布的期望。 注意的是，这里的 $x$ 不是输入，而是输出，**输入不当做随机变量处理，(仅仅是回归问题，分类问题中输入变量是随机变量，要不就不会存在(X,Y)联合分布一说)!!!，输出才是!**
- 一个极好的参考例子参见《PRML》中$P_{28}-P_{31}$。

### MAP、贝叶斯估计、朴素贝叶斯估计、后验概率最大化准则

- 点估计：是用样本统计量(数理统计）来估计总体参数(概率论)，因为样本统计量为数轴上某一点值，估计的结果也以一个点的数值表示，所以称为点估计。总体参数如期望、方差、相关系数等，就是样样本的期望、方差等来代替概率分布中的对应的特征值。
- `MAP` 和 `MLE` 都是点估计，通过各自的目标函数求导获得对应的参数；  
- 贝叶斯估计使用的是 $\theta$ 的全分布，通过公式$(2)$获得新的输出的概率分布，然后用期望作为新输出的值。但是最大后验估计是对公式$(1)$进行求最值(一般是公式$(1)$负对数的最小值)，获得对参数的点估计；  
- 既然有贝叶斯估计(原则上应该使用参数$\theta$的概率分布来进行预测，那么为什么常常需要MAP？这是因为对对大多数模型而言，贝叶斯后验估计的计算非常棘手，首先$P(\theta|D)难以确定，其次公式$(2)$积分更难计算，一般只有服从高斯分布的时候才容易些。所以后验概率最大化(点估计)提供了一个近似的可行解，我们可以采用先验影响点估计的选择来利用贝叶斯的优点，而不是简单的进行最大似然估计;
- 后验概率最大化准则：这个是预测的时候采用的策略，当模型是概率模型的时候，这个是在分类的问题中所使用的。就是给定一个新的输入，判断是哪一个类别的时候，选择$P(Y=c_k|x)$最大的$c_k$作为预测。 **后验概率最大化准则是大部分分类问题(用概率模型）所采的策略，比如logic和softmax，又或者是使用卷积神经网络对图片分类，使用logic或者是softmax最为损失函数，一般都是；为什么不是一定的是呢？以用logic回归判断是否有癌症进行二分类问题为例，一般不是$P(Y=癌症|x)>0.5$就判断是癌症，为了减少癌症人群中误判的概率，可能>0.4就认为是得了癌症；这个又涉及到分类器的评价标准上了！**

- 朴素贝叶斯法：基于贝叶斯定理和**特征条件独立假设**的分类方法。参见《统计学习方法》。输入是特征向量 $x\in X$，输出是类标记$y\in Y$，$Y= \{c_1,...,c_K\}$，训练数据集是 $T=\{(x_1,y_1),(x_2,y_2),...,(x_m,y_m)\}$ 是由 $P(X,Y)$ **独立同分布**产生的。目标是给定新的输入$x$，通过学习到的模型计算后验概率分布$P(Y=c_k|X=x)$，因为$y$可以取 $K$ 个值，所以需要计算 $K$个后验概率$P(Y=c_k|X=x), k=1,...,K$，然后通过后验概率最大化准则来确定输出是哪一类。
    $$
    P(Y=c_k|X=x) = \frac{P(X=x|Y=c_k)P(Y=c_k)}{P(X=x)}      \tag{3}
    $$
    上式中，不论$Y$取哪一类，分母$P(X=x)$都是相同的，而我们的目标只是找到取哪一类后验概率最大，这样的话，就没有必要精确的计算出后验概率，只要算出一下即可：  
    $$
    y = \argmax_{c_k} P(Y=c_k)P(X=x|Y=c_k)  \tag{4} 
    $$
    但是这里有一个问题，就是 $X$ 是n维变量，假设第$j$维 $x^{(j)}$ 可以取 $S_j$ 个离散值，那么 $P(X=x|Y=c_k)$ 概率分布空间将非常大，总共要计算 $K\prod_{j=1}^{n} S_j$ 个，一方面计算量大，另一方面样本量少，一些取值可能在样本中没有出现，但并不表示其为0。因此如果直接计算，是不可取的。  
    我们通过 **条件独立性假设** 来减少计算量和概率分布空间，即  
    $$
    P(X=x|Y=c_k) = P(x^{(1)},...,x^{(n)}|Y=c_k) = \prod_{j=1}^n P(x^{(j)}|Y=c_k)
    $$
    现在的计算量就只是 $K\sum_j^n S_j$ 个。
    公式 $(4)$ 变成为
    $$
    y = \argmax_{c_k} P(Y=c_k)\prod_{j=1}^n P(x^{(j)}|Y=c_k)  \tag{5}
    $$
    朴素贝叶斯法中，学习意味着估计 $P(Y=c_k)$ 和 $P(x^{(j)}|Y=c_k)$，这个可以使用最大似然估计。估计出的结果有很明确的意义：
    $$
    P(Y=c_k) = \frac{\sum_{i=1}^m I(y_i=c_k)}{m}   \tag{6}
    $$
    就是输出是 $c_k$ 的数目 / 样本总数；  
    假设第 $j$ 个特征 $x^{(j)}$ 可以取到的集合是 $\{a_{j1},...a_{jS_j}\}$，条件概率 $P(X^{(j)}=a_{jl}|Y=c_k) 的估计：
    $$
    P(X^{(j)}=a_{jl}|Y=c_k) = \frac{\sum_{i=1}^m I(x_i^{(j)}=a_{jl}, y_i=c_k)}{\sum_{i=1}^m I(y_i=c_k)} \tag{7}
    $$
    就是两者共同出现的数目 / 输出是 $c_k$ 的数目。  
    

### 后验概率最大化准则 和 期望风险最小

- 损失函数：度量模型一次预测的好坏，就是单个样本造成的损失，$L(y,f(x))$。
- 风险函数(期望损失)：度量平均意义下模型的好坏，模型的输入输出$(X,Y)$服从概率分布$P(X,Y)$，所以损失函数的期望：
    $$
    R_{exp}(f) = E_P[L(Y,f(X))] = \int_{x\times y} L(y,f(x))P(x,y)dxdy  \tag{8}
    $$
    **学习的目标是就是选择期望风险最小的模型**，但是公式$(8)$是不可用的，因为并不知道联合概率 $P(X，Y)$，如果我们知道，那么1是可以通过积分直接可以求出$P(Y|X)$，然后通过后验概率最大化预测出 $y$ 的类别了。或者不用积分，因为：
    $$
    P(Y|X) = \frac{P(X,Y)}{P(X)}  \tag{9}
    $$
    因为分母对所有的Y的类别都是相同的，因此后验概率最大也就是联合分布概率最大，这样不用求的$P(Y|X)$的精确解，也一样可以预测(参见朴素贝叶斯法)。  
    这是因为不知道联合概率，所以才需要学习，但是学习的目标是期望风险最小，这个又要用到联合概率，这样就造成了一个病态问题(ill-formed problem)。  
    实际应用中，我们用训练集的平均损失来估计(代替)期望风险。训练集的平均损失叫做经验风险：
    $$
    R_{emp}(f) = \frac{1}{m} \sum_{i=1}^m L(y_i, f(x_i))  \tag{10}
    $$
    根据大数定律，当样本容量$m$无线趋近于无穷，经验风险$R_{emp}(f)$趋近于期望风险$R_{exp}(f)$。但现实的样本数目有限，经验风险往往并不理想，因此需要对经验风险进行矫正。这就涉及到监督学习的两个策略：经验风险最小化和结构风险最小化。  

- 经验风险最小化：
    $$
    \min \frac{1}{m} \sum_{i=1}^m L(y_i, f(x_i))   \tag{11}
    $$
    该策略当样本很大的时候，能有很好的学习效果(根据大数定律)。 **当模型是条件概率分布，损失函数是对数损失时，经验风险最小化等价于极大似然估计**，极大似然估计：
    $$
    \max \prod_{i=1}^m P(y_i|x_i) \tag{12}
    $$
    而对数损失函数:
    $$
    L(Y,P(Y|X)) = -\log P(Y|X)
    $$
    $P(Y|X)$ 越大，损失越小，对应的经验损失就是：
    $$
    -\sum_{i=1}^m log P(y_i|x_i) = -log \prod_{i=1}^m P(y_i|x_i)   \tag{13}
    $$
    公式$(12)(13)$可以看成是等价的。

- 结构风险最小化： 就是加上了惩罚函数。

### 分类器的评价标准

分类器的评价标准是如何影响分类器的学习的？在学习过程中，评价标准能不能参与其中？还是只是事后的检测？  
其实这个问题问的很蠢，因为分类器总要有一个评价指标，对于分类问题最简单的就是 `准确率`，通过观察每个 `epoch` 的准确率，从而来判断训练的效果的，其他的评价指标自然也是一样的。其他的指标有 `召回率(recall)`、 `精确率(precision)`。

