## 常用概率分布的思考(上)

[TOC]

### 对于二元变量

 #### 经常用到bernoulli分布，二项式分布，beta分布

* bernoulli 分布

  $x$取值是二元的$\left\{0,1\right\}$，假设
  $$
  p(x=1/ \mu)=\mu \tag 1
  $$
  那么$x\sim bern(x/\mu)$:
  $$
  bern(x/\mu)=\mu^x(1-\mu)^{1-x} \tag 2
  $$
  从而：
  $$
  \begin{aligned}
  E(x)=\mu \\ 
  var(x)=\mu(1-\mu)
  \end{aligned} \tag 3
  $$
  极大似然估计：

  ​	对于训练集$D=\left\{x_1,...,x_N \right\}​$ ，假设观察值独立同分布，那么对数似然函数为：
  $$
  LL=\log p(D/ \mu)=\log \prod_{i=1}^{N}\mu^{x_i}(1-\mu)^{1-{x_i}}=\sum_{i=1}^N(x_i\log \mu+(1-x_i)log(1-\mu)) \tag 4
  $$
  最大化$LL$，可得：
  $$
  \mu_{ML}=\frac {1}{N} \sum_{i=1}^N x_i \tag 5
  $$
  说明：假设数据集$D$是$N$次抛硬币正反面的样本，如果$N$次皆抛正面，那么极大似然估计抛正面的概率是1，显然是不合理的，这说明，极大似然估计容易过拟合，即过于遵从样本的数据特征。

* 二项分布

  当做$N$次试验，$m$次为正，以$m$为变量，那么其概率分布：
  $$
  p(m)=C_N^m\mu^m(1-\mu)^{N-m}=\frac {N!}{(N-m)!m!}\mu^m(1-\mu)^{N-m}   \tag 6
  $$
  对于二巷分布的期望$E(m)$和$Var(m)$的求法这里要说明一下：

  当求期望$E(m)$和$Var(m)$，若按照对应的公式求，发现是很困难的，比如：
  $$
  E(m)=\sum_{m=0}^N mp(m) \\
  Var(m)=E[m^2]-E^2[m]
  $$
  显然是没法下手的，但通过把$m$看成是多个独立变量和时，通过下面的性质可轻松求出来：
  $$
  E(\sum_{i=1}^Nx_i)=\sum_{i=1}^NE(x_i)  \\
  Var(\sum_{i=1}^Nx_i)=\sum_{i=1}^NVar(x_i) \tag 7
  $$
  对于期望公式很容易证明，现在证明方差公式：
  $$
  \begin{aligned}
  Var(\sum_{i=1}^Nx_i)
  &=E[\sum_{i=1}^Nx_i-E(\sum_{i=1}^Nx_i)]^2 \\
  &=E[\sum_{i=1}^Nx_i-\sum_{i=1}^NE(x_i)]^2 \\
  &=E[\sum_{i=1}^N(x_i-E(x_i))]^2 \\
  &=E[\sum_{i=1}^N\sum_{j=1}^N(x_i-E(x_i))(x_j-E(x_j))] \\
  &=\sum_{i=1}^N\sum_{j=1}^NE[(x_i-E(x_i))(x_j-E(x_j))]\\
  &=\sum_{i=1}^N E[(x_i-E(x_i))^2] \\
  &=\sum_{i=1}^N Var(x_i)
  \end{aligned} \tag 8
  $$
  说明一下，上式第5步到第6步，当$i \neq j$时，$E[(x_i-E(x_i))(x_j-E(x_j))]=E[x_i-E(x_i)]E[x_j-E(x_j)]=0$。

  假设正面为1，反面为0，那么有：
  $$
  m=\sum_{i=1}^N x_i
  $$
  因为每一次抛都是独立的，则有：
  $$
  E(m)=E(\sum_{i=1}^Nx_i)=\sum_{i=1}^NE(x_i)=N\mu \\
  Var(m)=Var(\sum_{i=1}^Nx_i)=\sum_{i=1}^N Var(x_i)=N\mu (1-\mu)   \tag{9}
  $$

* beta分布

  介绍beta分布之前，先要说一下$gamma$函数：
  $$
  \Gamma(x)=\int_0^{+\infty}u^{x-1}e^{-u}du   \tag{10}
  $$
  $\Gamma(x)​$具体形式可能记不住，但是它的性质很有意思，很有用：
  $$
  \Gamma(x+1)=x \Gamma(x)   \tag{11}
  $$
  上式通过分布积分可以很容易证明。

  由于$\Gamma(1)=1$，故当$x$取整数的时候：
  $$
  \Gamma(x+1)=x!   \tag{12}
  $$
  也就说，阶乘是$\Gamma(x)​$函数在自变量取整数时的值。

  现在来说beta分布，beta分布产生源于共轭分布，当我们用最大后验估计来估计参数时，要计算后验分布，当然用最大后验估计是不需要完全计算出后验估计的（因为后验估计正比与先验分布和似然函数的乘积）。应该说是当用bayesian估计时，要计算后验概率，但是我们知道，计算后验概率不容易。但当我们选择合适的先验概率，使得后验概率和先验概率是同类型的分布，那么只要再进行归一化就可以求出后验概率了。

  对于训练集$D=\left\{x_1,...,x_N \right\}​$ ，假设观察值独立同分布，那么似然函数为：
  $$
  p(D/\mu)=\prod_{i=1}^{N}\mu^{x_i}(1-\mu)^{1-x_i}=\mu^m(1-\mu)^{N-m}  \tag {13}
  $$
  其中$m​$是训练集D中$x=1​$的个数。

  **这里需要尤其注意一下，就是$(13)$式和二项分布$(6)$式差别是缺少$(6)$式中的归一化系数，那么为什么会这样呢？这是因为所取变量不同，自然求的概率不同，似然函数的变量是$D=\left\{x_1,...,x_N \right\}$ 联合概率，而二项分布取的是$m=\sum_{i=1}^N x_i$**。 

  后验概率：
  $$
  p(\mu/D) \propto p(D/\mu)p(\mu)   \tag{14}
  $$
  结合式$(13)$，当我们选择先验概率$p(\mu)$满足：
  $$
  p(\mu) \propto \mu^a(1-\mu)^b  \tag {15}
  $$
  那么后验概率就有：
  $$
  p(\mu/D) \propto \mu^{m+a}(1-\mu)^{N-m+b}  \tag{16}
  $$
  此时只要对其归一化(Normalization)，就可以求出$p(\mu/D)$。

  首先要对式$(15)$进行归一化，使得成为先验概率$p(\mu)$的概率分布，这就引出来beta分布：
  $$
  p(\mu)=\frac {\Gamma(a+b)}{\Gamma(a)\Gamma(b)}\mu^{a-1}(1-\mu)^{b-1}   \tag{17}
  $$
  这里$a,b$可以为整数，也可以为小数，但上面讲过，对于$\Gamma(x)$函数，当$x$为整数时，我们有：$\Gamma(n+1)=n!$，所以在推导过程中，不妨将$a,b​$看出整数，则：
  $$
  p(\mu)=\frac {\Gamma(a+b)}{\Gamma(a)\Gamma(b)}\mu^{a-1}(1-\mu)^{b-1}=\frac {(a+b-1)!}{(a-1)!(b-1)!}\mu^{a-1}(1-\mu)^{b-1}   \tag{18}
  $$
  我们来证明$p(\mu)$作为一个概率分布所需要满足的条件：$\int_0^1p(\mu)d\mu=1​$
  $$
  \begin{aligned}
  \int_0^1p(\mu)d\mu
  &=\int_0^1 \frac {(a+b-1)!}{(a-1)!(b-1)!}\mu^{a-1}(1-\mu)^{b-1}d\mu  \\
  &=\frac {(a+b-1)!}{(a-1)!(b-1)!} \int_0^1 \mu^{a-1}(1-\mu)^{b-1}d\mu
  \end{aligned} \tag{19}
  $$
  我们来求上式的积分：
  $$
  \begin{aligned}
  \int_0^1 \mu^{a-1}(1-\mu)^{b-1}d\mu
  &=\int_0^1 (1-\mu)^{b-1}d\mu^a \\
  &=\frac {(b-1)}{a} \int_0^1 \mu^a(1-\mu)^{b-2}d\mu \\
  &=\frac {(b-1)!}{a(a+1)...(a+b-2)} \int_0^1 \mu^{a+b-2}d\mu \\
  &=\frac {(b-1)!}{a(a+1)...(a+b-1)}
  \end{aligned} \tag{20}
  $$
  上式第2步到第3步不断用到分部积分，代入到$(19)$式得证。

  这里给出beta分布的期望，同样可以通过分部积分求出，下面推导会用到：
  $$
  E(\mu)=\int_0^1 \mu p(\mu)d\mu=\frac {a}{a+b} \tag{20-1}
  $$
  这是很符合直觉的，样本为正的先验概率就是假定为：正的个数/总的个数

  现在考察后验概率分布式$p(\mu/D)$:
  $$
  p(\mu/D) \propto p(D/\mu)p(\mu) \propto \mu^{a+m-1}(1-\mu)^{b+l-1}   \tag{21}
  $$
  其中$l=N-m$，是样本取值为0的个数。

  就可以用beta函数来归一化后验概率：
  $$
  p(\mu/D)=\frac {\Gamma(m+l+a+b)}{\Gamma(m+a)\Gamma(l+b)}\mu^{a+m-1}(1-\mu)^{b+l-1}  \tag{22}
  $$
  现在通过最大后验估计来估计参数$\mu$，上式对$\mu$进行求导，得出最大后验估计：
  $$
  \mu_{MAP}=\frac {a+m-1} {m+l+a+b-2}=\frac {a+m-1} {N+a+b-2}   \tag{23}
  $$
  此时，即使样本取值都为0，即$m=N$，最大后验估计出的$\mu$也不为0，这样就在一定程度上避免了过拟合。

  当采用bayesian估计时：
  $$
  p(x=1/D)=\int_0^1p(x=1/\mu)p(\mu/D)d\mu=\int_0^1\mu p(\mu/D)d\mu=E[\mu/D]  \tag{24}
  $$
  从上式可以看出，结果是关于beta分布的期望， 参照式$(20-1)$得：
  $$
  p(x=1/D)=\frac {a+m} {m+l+a+b}  \tag{25}
  $$
  同样可以在一定程度上避免过拟合，并期可解释性更强。

## 多项式分布

上面的分析的是样本标签是2个时候的所采取的方法，当样本有$K$个结果时，将如何处理？

对于$X$，可能的取值为$\left\{C_k\right\}_{k=1}^K$，可以采用"one-hot"编码方式，比如$X=C_k$，则可以将$X=(0,0,...,1,0,0)$，该向量的第$k$个元素为1，其他为0。这样，我们就可以表示出$p(x)​$的概率：
$$
p(x)=\prod_{k=1}^K\mu_k^{x^k}\\
s.t. \ \sum_{k=1}^K \mu_k=1   \tag{26}
$$
其中$x^k$是$x$的第$k$个元素。

则似然函数：
$$
\begin{aligned}
p(D/\boldsymbol{\mu})
&=P(D/\mu_1,...,\mu_K)\\
&=\prod_{i=1}^N \prod_{k=1}^K \mu_k^{x_i^k}\\
&=\prod_{k=1}^K \mu_k^{m_k}
\end{aligned}   \tag{27}
$$
上式中$m_k$是样本$D$中第$k$个元素取1的个数，$m_k=\sum_{i=1}^Nx_i^k$。

但是上面的并不是多项式分布，多项式分布是$p(m_1,...,m_K|N,\boldsymbol \mu)=\left(\frac{N!}{m_1!...m_K!}\right)\prod_{k=1}^K \mu_k^{m_k}$，那$(26)$是什么呢？是分类分布(categorical distribution)。

当我们想用bayesian方法时，同样要求参数的后验估计。参照二项问题的方法，如果先验分布：
$$
p(\boldsymbol{\mu})=P（\mu_1,...,\mu_K) \propto \prod_{k=1}^K \mu_k^{n_k-1}   \tag{28}
$$
则后验估计：
$$
P（\boldsymbol{\mu}/D) \propto P（\boldsymbol{\mu})P（D/\boldsymbol{\mu}) \propto \prod_{k=1}^K \mu_k^{m_k+n_k-1} \tag{29}
$$
那么总的来说，如果我们能把$\prod_{k=1}^K \mu_k^{n_k-1}​$归一化使其成为概率分布，那么就可以用同样的方式来归一化$\prod_{k=1}^K \mu_k^{m_k+n_k-1} ​$，这样先验就和后验共轭了。

参照beta分布，可较为容易的归一化$\prod_{k=1}^K \mu_k^{n_k-1}$：
$$
p(\boldsymbol{\mu}/\alpha)=\frac {\Gamma(\alpha_0)}{\Gamma(\alpha_1)...\Gamma(\alpha_K)}\prod_{k=1}^K\mu_k^{\alpha_k-1}  \tag{30}
$$
这就是鼎鼎大名的$Dirichlet$分布，其中$\alpha_0=\sum_{k=1}^{K}\alpha_k$。

Dirichlet distribution的归一化采用的公式是：
$$
\int p(\boldsymbol \mu|\alpha)d\boldsymbol \mu=\int...\int \frac {\Gamma(\alpha_0)}{\Gamma(\alpha_1)...\Gamma(\alpha_K)} (1-\sum_{j=1}^{K-1}\mu_j)^{(\alpha_K-1)} \prod_{k=1}^{K-1}\mu_k^{\alpha_k-1}d\mu_1...d\mu_{(K-1)}  \tag{30.1}
$$
单个元素的期望：
$$
E_{p(\boldsymbol \mu|\alpha)}[\mu_k]=\int...\int \frac {\Gamma(\alpha_0)}{\Gamma(\alpha_1)...\Gamma(\alpha_K)} (1-\sum_{j=1}^{K-1}\mu_j)^{(\alpha_K-1)} \mu_k\prod_{i=1}^{K-1}\mu_k^{\alpha_i-1}d\mu_1...d\mu_{(K-1)}=\frac{\alpha_k}{\alpha_0}    \tag{30.2}
$$
则后验分布就是：
$$
p(\boldsymbol{\mu}/D,\alpha)=\frac {\Gamma(\alpha_0+N)}{\Gamma(\alpha_1+m_1)...\Gamma(\alpha_K+m_K)}\prod_{k=1}^K\mu_k^{m_k+\alpha_k-1} \tag{31}
$$

## 总结 

+  bernuolli distribution : 二分类
  $$
  x\sim Ber(x|\mu)\\
  p(x=1)=\mu \\
  似然函数：L=\prod_{i=1}^{N}\mu^{x_i}(1-\mu)^{(1-x_i)}
  $$

+ binomial distribution：
  $$
  p(m|N,\mu)=\frac {N!}{(N-m)!m!}\mu^m(1-\mu)^{N-m}
  $$
  它可以看成是N次伯努利试验，但是变量是$m=\sum_{i=1}^N x_i$，以抛硬币为例，表示N次试验m次为正的概率。伯努利的似然函数也是进行了N次独立试验，似乎应该是binomial distribution来表示其联合概率，但是由于似然函数$L=p(\bold x)$，联合概率$p(\bold x)$的变量是$\bold x=(x_1,...,x_N)$，而不是$m=\sum_{i=1}^N x_i$，故不可以用binomial distribution 来表示。

+ categorical distribution：多分类
  $$
  p(x)=\prod_{k=1}^K\mu_k^{x^k}\\
  s.t. \ \sum_{k=1}^K \mu_k=1   \\
  似然函数：\\
  \begin{aligned}
  L=p(D/\boldsymbol{\mu})
  &=P(D/\mu_1,...,\mu_K)\\
  &=\prod_{i=1}^N \prod_{k=1}^K \mu_k^{x_i^k}\\
  &=\prod_{k=1}^K \mu_k^{m_k}
  \end{aligned}
  $$

+ multinational distribution：
  $$
  p(m_1,...,m_K|N,\boldsymbol \mu)=\left(\frac{N!}{m_1!...m_K!}\right)\prod_{k=1}^K \mu_k^{m_k}\\
  s.t. \ \sum_{k=1}^K \mu_k=1 
  $$
  它可以看成是N次分类试验，与categorical distribution的关系和bernuolli distribution与binomial distribution 相似。

  **实际应用中，多用bernuolli distribution 和categorical distribution。**

+ 共轭先验

  从Bernuolli distribution 和 Categorical distribution 的似然函数可以看出，它们各自正比于binomial distribution和multinational distribution，而binomial distribution分布的参数的先验分布是Beta distribution，multinational distribution的参数的先验分布是Dirichlet distribution，所以Bernuolli distribution 和 Categorical distribution 的似然函数的中参数的先验分布分别是Beta distribution 和multinational distribution。

  **这里要说明的是，先验分布是对参数而言的，不是说某某分布的先验分布是某某分布，因为对多参数而言的似然函数，对于不同的参数有不同的先验分布，因为先验分布也是某一变量的分布，你要指明这个变量，也就要指明似然函数中是某某参数。**

